# Spring Boot 로그 기반 이상치 탐지 시스템 연구 보고서

## 1. 연구 배경 및 목적

### 1.1 연구 배경

현대 소프트웨어 시스템은 복잡한 마이크로서비스 아키텍처로 구성되어 있으며, 수많은 서비스 간 상호작용이 발생합니다. 이러한 환경에서 시스템 장애나 성능 저하는 비즈니스에 심각한 영향을 미칠 수 있습니다. 

**문제점:**
- 대규모 로그 데이터에서 이상 패턴을 수동으로 탐지하기 어려움
- 장애 발생 후에야 문제를 인지하는 사후 대응 방식
- 다양한 서비스(manager, user, research, smeta, code, cert 등)의 로그를 통합 분석 필요
- 실시간 이상 탐지 및 조기 경고 시스템 부재

### 1.2 연구 목적

본 연구의 목적은 다음과 같습니다:

1. **자동화된 이상 탐지**: Spring Boot 애플리케이션 로그를 자동으로 분석하여 이상 패턴을 탐지
2. **다중 방법론 통합**: 통계적 방법과 머신러닝 기반 방법을 결합하여 탐지 정확도 향상
3. **조기 경고 시스템**: 문제 발생 전에 이상 징후를 감지하여 사전 대응 가능
4. **확장 가능한 시스템**: 다양한 로그 형식과 서비스에 적용 가능한 범용 시스템 구축

### 1.3 연구의 기대 효과

- **운영 효율성 향상**: 수동 모니터링 시간 절감
- **장애 예방**: 조기 이상 탐지로 장애 발생 전 대응 가능
- **시스템 안정성 향상**: 지속적인 모니터링을 통한 시스템 건강도 관리
- **비용 절감**: 장애로 인한 다운타임 및 복구 비용 감소

---

## 2. 데이터셋 설명

### 2.1 데이터 소스

**데이터 위치**: `/pattern/prelog/logs/backup/`

**데이터 형식**: Spring Boot 애플리케이션 로그 파일 (`.log` 확장자)

**데이터 규모**:
- 총 로그 파일 수: 100개 이상
- 파일 크기: 수 KB ~ 수백 MB
- 로그 라인 수: 수백 ~ 수만 라인/파일

### 2.2 로그 파일 구조

#### 2.2.1 파일 명명 규칙
```
{서비스명}_{날짜}_{시간}.log

예시:
- manager_250710_15:50:15.log
- user_250710_15:38:20.log
- smeta_250710_14:18:36.log
- research_250709_15:27:12.log
- code_250702_19:33:28.log
- cert_250702_19:31:23.log
```

#### 2.2.2 서비스 유형
1. **manager**: 관리자 서비스 로그
2. **user**: 사용자 서비스 로그
3. **research**: 연구 서비스 로그
4. **smeta**: 메타데이터 서비스 로그
5. **code**: 코드 서비스 로그
6. **cert**: 인증 서비스 로그
7. **gateway**: 게이트웨이 로그
8. **eureka**: 서비스 디스커버리 로그
9. **fs**: 파일 시스템 서비스 로그

### 2.3 로그 형식

#### 2.3.1 표준 로그 형식
```
{타임스탬프} {로그레벨} {프로세스ID} --- [{스레드명}] {클래스경로} : {메시지}
```

**예시:**
```
2025-07-02 15:59:36.514  INFO 12185 --- [           main] k.r.b.f.c.Application                    : Starting Application using Java 17.0.14 on develop-server with PID 12185
```

#### 2.3.2 로그 구성 요소

| 구성 요소 | 설명 | 예시 |
|---------|------|------|
| 타임스탬프 | 로그 발생 시간 | `2025-07-02 15:59:36.514` |
| 로그 레벨 | 로그 중요도 | `INFO`, `WARN`, `ERROR`, `DEBUG` |
| 프로세스 ID | Java 프로세스 ID | `12185` |
| 스레드명 | 실행 스레드 이름 | `main`, `http-nio-8080-exec-1` |
| 클래스 경로 | 로그를 발생시킨 클래스 | `k.r.b.f.c.Application` |
| 메시지 | 실제 로그 내용 | `Starting Application...` |

### 2.4 데이터 전처리 과정

#### 2.4.1 파싱 단계
1. **정규표현식 기반 파싱**: Spring Boot 로그 패턴 매칭
2. **타임스탬프 변환**: 문자열 → datetime 객체
3. **에러 키워드 탐지**: Exception, Error, Failed 등 키워드 확인
4. **메타데이터 추출**: 파일명, 라인 번호 등 저장

#### 2.4.2 특징 추출 단계
- **시간 윈도우 단위 집계**: 10분 단위로 로그 그룹화
- **통계 특징 계산**:
  - 총 로그 수
  - 에러/경고/정보 로그 수 및 비율
  - 고유 클래스/스레드 수
  - 평균 메시지 길이
  - 예외 발생 횟수 및 비율

### 2.5 데이터 분할 전략

**학습/검증/테스트 분할**:
- **학습 데이터 (80%)**: 모델 학습 및 기준선 통계 계산
- **검증 데이터 (10%)**: 모델 성능 평가 및 하이퍼파라미터 튜닝
- **테스트 데이터 (10%)**: 최종 모델 성능 평가

**분할 방법**: 시간순 정렬 후 순차적 분할 (시간적 의존성 고려)

---

## 3. 구현 방법 및 적용 모델 설명

### 3.1 전체 시스템 아키텍처

```
┌─────────────────────────────────────────────────────────┐
│                    로그 파일 수집                          │
│         (logs/backup/*.log)                              │
└────────────────────┬────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────┐
│              1. 로그 파싱 (SpringBootLogParser)          │
│  - 정규표현식 기반 파싱                                   │
│  - 타임스탬프, 레벨, 클래스, 메시지 추출                  │
└────────────────────┬────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────┐
│           2. 특징 추출 (LogAnomalyDetector)              │
│  - 시간 윈도우별 집계 (10분 단위)                        │
│  - 통계 특징 계산 (에러율, 로그 빈도 등)                 │
└────────────────────┬────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────┐
│        3. 데이터 분할 (80% 학습 / 10% 검증 / 10% 테스트) │
└────────────────────┬────────────────────────────────────┘
                     │
        ┌────────────┴────────────┐
        │                         │
        ▼                         ▼
┌──────────────────┐    ┌──────────────────┐
│  4. 모델 학습     │    │  5. 성능 평가     │
│  - 기준선 통계    │    │  - 검증 데이터    │
│  - ML 모델 학습   │    │  - 정확도/재현율  │
└──────────────────┘    └──────────────────┘
        │
        ▼
┌─────────────────────────────────────────────────────────┐
│           6. 이상치 탐지 (다중 방법론)                    │
│  - 통계적 이상치 탐지                                    │
│  - 에러 급증 탐지                                         │
│  - 비정상 패턴 탐지                                       │
│  - ML 기반 이상치 탐지                                    │
└────────────────────┬────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────┐
│           7. 결과 리포트 및 저장                         │
│  - CSV 파일 저장                                          │
│  - 모델 저장 (pickle)                                     │
└─────────────────────────────────────────────────────────┘
```

### 3.2 단계별 상세 구현

#### 3.2.1 단계 1: 로그 파싱 (SpringBootLogParser)

**목적**: 비구조화된 로그 텍스트를 구조화된 데이터로 변환

**구현 방법**:
```python
LOG_PATTERN = re.compile(
    r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d{3})\s+'  # 타임스탬프
    r'(\w+)\s+'                                              # 로그 레벨
    r'(\d+)\s+'                                              # 프로세스 ID
    r'---\s+'                                                # 구분자
    r'\[([^\]]+)\]\s+'                                       # 스레드명
    r'([^\s:]+)\s*:?\s*'                                     # 클래스 경로
    r'(.*)'                                                  # 메시지
)
```

**처리 과정**:
1. 각 로그 라인을 정규표현식으로 매칭
2. 매칭된 그룹을 파싱하여 딕셔너리로 변환
3. 에러 키워드 탐지 (Exception, Error, Failed 등)
4. 메타데이터 추가 (파일명, 라인 번호)

**출력 형식**:
```python
{
    'timestamp': datetime,
    'level': str,           # INFO, WARN, ERROR, DEBUG
    'pid': str,
    'thread': str,
    'class_path': str,
    'message': str,
    'is_error': bool,
    'message_length': int,
    'has_exception': bool,
    'file_path': str,
    'line_number': int
}
```

#### 3.2.2 단계 2: 특징 추출 (LogAnomalyDetector.extract_features)

**목적**: 파싱된 로그를 머신러닝 모델이 사용할 수 있는 수치형 특징으로 변환

**시간 윈도우 설정**: 10분 단위 (`dt.floor('10T')`)

**추출되는 특징**:

| 특징명 | 설명 | 계산 방법 |
|--------|------|----------|
| `total_logs` | 윈도우 내 총 로그 수 | `len(window_df)` |
| `error_count` | 에러 로그 수 | `is_error.sum()` |
| `warn_count` | 경고 로그 수 | `level == 'WARN'` |
| `error_rate` | 에러 비율 | `error_count / total_logs` |
| `warn_rate` | 경고 비율 | `warn_count / total_logs` |
| `unique_classes` | 고유 클래스 수 | `class_path.nunique()` |
| `unique_threads` | 고유 스레드 수 | `thread.nunique()` |
| `avg_message_length` | 평균 메시지 길이 | `message_length.mean()` |
| `exception_count` | 예외 발생 횟수 | `has_exception.sum()` |
| `exception_rate` | 예외 발생 비율 | `exception_count / total_logs` |
| `info_count` | 정보 로그 수 | `level == 'INFO'` |
| `debug_count` | 디버그 로그 수 | `level == 'DEBUG'` |
| `top_class` | 가장 많이 나온 클래스 | `class_path.value_counts().idxmax()` |
| `top_class_count` | 최빈 클래스의 로그 수 | `class_path.value_counts().max()` |

**특징 추출 예시**:
```python
# 입력: 10분간의 로그 데이터
logs = [
    {'timestamp': '2025-07-02 15:00:00', 'level': 'INFO', ...},
    {'timestamp': '2025-07-02 15:01:00', 'level': 'ERROR', ...},
    ...
]

# 출력: 시간 윈도우별 특징
features = {
    'time_window': '2025-07-02 15:00:00',
    'total_logs': 150,
    'error_count': 5,
    'error_rate': 0.033,
    'warn_count': 2,
    ...
}
```

#### 3.2.3 단계 3: 데이터 분할

**분할 비율**: 80% 학습 / 10% 검증 / 10% 테스트

**분할 방법**:
```python
# 시간순 정렬
features_df = features_df.sort_values('time_window')

# 분할 인덱스 계산
train_end = int(total_samples * 0.8)      # 80%
val_end = train_end + int(total_samples * 0.1)  # 10%

# 데이터 분할
train_df = features_df.iloc[:train_end]
val_df = features_df.iloc[train_end:val_end]
test_df = features_df.iloc[val_end:]
```

**시간적 의존성 고려**: 시간순으로 분할하여 미래 데이터로 과거를 예측하는 문제 방지

#### 3.2.4 단계 4: 기준선 통계 계산

**목적**: 정상 상태의 통계적 특성을 파악하여 이상치 판단 기준 설정

**계산되는 통계량**:
- 평균 (mean)
- 표준편차 (std)
- 중앙값 (median)
- 25% 분위수 (q25)
- 75% 분위수 (q75)
- 95% 분위수 (q95)

**적용 특징**: 모든 수치형 특징에 대해 계산

**사용 예시**:
```python
baseline_stats = {
    'error_rate_mean': 0.026,      # 평균 에러율 2.6%
    'error_rate_std': 0.015,       # 표준편차 1.5%
    'error_rate_q95': 0.050,      # 95% 분위수 5.0%
    ...
}
```

#### 3.2.5 단계 5: 머신러닝 모델 학습

##### 5-1. Isolation Forest

**모델 설명**:
- **알고리즘**: Isolation Forest (IF)
- **원리**: 이상치를 격리하기 쉬운 특성을 이용하여 이상치 탐지
- **장점**: 
  - 비지도 학습 (라벨 불필요)
  - 고차원 데이터 처리 가능
  - 빠른 학습 및 예측 속도

**하이퍼파라미터**:
```python
IForest(
    contamination=0.1,      # 이상치 비율 (10%)
    random_state=42         # 재현성을 위한 시드
)
```

**학습 과정**:
1. 특징 데이터 정규화 (StandardScaler)
2. Isolation Forest 모델 학습
3. 모델 저장

##### 5-2. AutoEncoder

**모델 설명**:
- **알고리즘**: AutoEncoder (AE)
- **원리**: 정상 데이터를 학습하여 재구성 오차가 큰 데이터를 이상치로 판단
- **장점**:
  - 비선형 패턴 학습 가능
  - 특징 추출 및 차원 축소 효과

**동적 파라미터 조정**:
```python
# 데이터 크기에 따른 자동 조정
if n_samples < 10:
    return None  # 데이터 부족
elif n_samples < 50:
    hidden_neurons = [16, 8, 16]
    epochs = 20
    batch_size = 8
else:
    hidden_neurons = [64, 32, 16, 32, 64]
    epochs = 50
    batch_size = 32
```

**하이퍼파라미터**:
```python
AutoEncoder(
    contamination=0.1,
    hidden_neurons=[64, 32, 16, 32, 64],  # 인코더-디코더 구조
    epochs=50,
    batch_size=32,
    dropout_rate=0.2,
    random_state=42
)
```

#### 3.2.6 단계 6: 이상치 탐지 방법론

##### 6-1. 통계적 이상치 탐지 (Z-score 기반)

**원리**: 기준선 통계 대비 3 표준편차 이상 벗어난 패턴 탐지

**공식**:
```
Z-score = |현재값 - 평균| / 표준편차
이상치 판단: Z-score > 3.0
```

**적용 특징**: 모든 수치형 특징에 대해 계산

**예시**:
```python
# 기준선: error_rate_mean = 0.026, error_rate_std = 0.015
# 현재값: error_rate = 0.080

z_score = |0.080 - 0.026| / 0.015 = 3.6

# z_score > 3.0 → 이상치로 판단
```

##### 6-2. 에러 급증 탐지

**원리**: 기준 에러율 대비 급격한 증가 감지

**임계값**: 기준 에러율의 5배 이상

**공식**:
```python
multiplier = 현재_에러율 / 기준_에러율
이상치 판단: multiplier > 5.0
```

**예시**:
```python
# 기준 에러율: 2.6%
# 현재 에러율: 19.71%

multiplier = 19.71 / 2.6 = 7.6배

# multiplier > 5.0 → 에러 급증으로 판단
```

##### 6-3. 비정상 패턴 탐지

**3가지 패턴 탐지**:

1. **에러 집중 패턴**
   - 특정 클래스에서 전체 에러의 50% 이상 발생
   - 버그가 특정 모듈에 집중된 경우 탐지

2. **로그 빈도 이상**
   - 평소 대비 로그 빈도가 급격히 증가/감소
   - Z-score > 3.0인 경우 이상으로 판단

3. **새로운 예외 타입**
   - 기존에 없던 새로운 예외 발생
   - 전체 예외의 1% 미만이면 새로운 예외로 간주

##### 6-4. ML 기반 이상치 탐지

**Isolation Forest**:
```python
# 예측
predictions = model.predict(X_scaled)  # 1=이상, 0=정상
scores = model.decision_function(X_scaled)  # 이상 점수
```

**AutoEncoder**:
```python
# 재구성 오차 계산
reconstruction_error = |원본 - 재구성값|
# 오차가 큰 경우 이상치로 판단
```

#### 3.2.7 단계 7: 성능 평가

**평가 지표**:

1. **정확도 (Accuracy)**
   ```
   Accuracy = (TP + TN) / (TP + TN + FP + FN)
   ```
   - 전체 예측 중 올바른 예측 비율

2. **정밀도 (Precision)**
   ```
   Precision = TP / (TP + FP)
   ```
   - 이상치로 예측한 것 중 실제 이상치 비율
   - False Positive를 줄이는 데 중요

3. **재현율 (Recall)**
   ```
   Recall = TP / (TP + FN)
   ```
   - 실제 이상치 중 탐지한 비율
   - False Negative를 줄이는 데 중요

4. **F1 점수**
   ```
   F1 = 2 * (Precision * Recall) / (Precision + Recall)
   ```
   - 정밀도와 재현율의 조화평균

5. **혼동 행렬 (Confusion Matrix)**
   ```
   [정상→정상  정상→이상]
   [이상→정상  이상→이상]
   ```

**라벨 생성 방법**:
```python
# 기준 에러율의 2배 이상이면 이상치로 간주
baseline_error_rate = baseline_stats['error_rate_mean']
threshold = baseline_error_rate * 2
true_label = (error_rate > threshold).astype(int)
```

### 3.3 모델 비교 및 선택 기준

| 모델 | 장점 | 단점 | 적용 시나리오 |
|------|------|------|--------------|
| **통계적 방법** | 해석 가능, 빠른 계산 | 선형 패턴만 탐지 | 명확한 임계값이 있는 경우 |
| **에러 급증 탐지** | 직관적, 빠른 탐지 | 단일 지표만 사용 | 에러율 모니터링에 특화 |
| **Isolation Forest** | 빠른 학습, 고차원 처리 | 하이퍼파라미터 튜닝 필요 | 범용 이상 탐지 |
| **AutoEncoder** | 비선형 패턴 학습 | 학습 시간 길음, 데이터 많아야 함 | 복잡한 패턴 탐지 |

### 3.4 시스템 통합 및 배포

**모델 저장**:
```python
model_data = {
    'baseline_stats': baseline_stats,
    'scaler': scaler,
    'models': models
}
pickle.dump(model_data, 'trained_model.pkl')
```

**새로운 데이터 탐지**:
```python
# 모델 로드
system.load_model('trained_model.pkl')

# 새로운 로그 분석
results = system.detect_anomalies_on_new_data(new_log_directory)
```

---

## 4. 추가 적용 방향 및 개선 사항

### 4.1 단기 개선 방향

#### 4.1.1 실시간 모니터링 시스템 구축

**현재**: 배치 처리 방식 (주기적 분석)
**개선**: 실시간 스트리밍 분석

**구현 방안**:
- **로그 스트리밍**: Kafka, Fluentd 등을 통한 실시간 로그 수집
- **윈도우 스트리밍**: 슬라이딩 윈도우 방식으로 실시간 특징 추출
- **이벤트 기반 알림**: 이상치 탐지 시 즉시 알림 (이메일, Slack, PagerDuty)

**예시 구조**:
```python
# 실시간 로그 스트리밍 처리
def stream_log_analysis():
    while True:
        new_logs = collect_recent_logs(window_minutes=10)
        features = extract_features(new_logs)
        anomalies = detect_anomalies(features)
        
        if anomalies:
            send_alert(anomalies)
        
        time.sleep(60)  # 1분마다 체크
```

#### 4.1.2 다중 서비스 통합 분석

**현재**: 개별 서비스 로그 분석
**개선**: 서비스 간 상관관계 분석

**구현 방안**:
- **서비스 간 의존성 분석**: A 서비스 에러 → B 서비스 에러 패턴 탐지
- **분산 추적 (Distributed Tracing)**: 요청이 여러 서비스를 거치는 경로 추적
- **통합 대시보드**: 모든 서비스의 이상치를 한 화면에서 모니터링

**예시**:
```python
# 서비스 간 상관관계 분석
def analyze_service_correlation():
    # manager 서비스 에러 발생
    manager_errors = detect_errors('manager')
    
    # 연관된 서비스 확인
    related_services = ['user', 'research', 'smeta']
    
    for service in related_services:
        service_errors = detect_errors(service, time_window=manager_errors.time)
        if correlation(manager_errors, service_errors) > 0.7:
            alert(f"{service} 서비스도 연쇄적으로 에러 발생")
```

#### 4.1.3 심층 로그 분석

**현재**: 기본적인 통계 특징만 사용
**개선**: 자연어 처리 기반 심층 분석

**구현 방안**:
- **로그 메시지 임베딩**: BERT, Word2Vec 등을 이용한 의미 분석
- **예외 스택 트레이스 분석**: 스택 트레이스 패턴 클러스터링
- **로그 시퀀스 분석**: LSTM, Transformer를 이용한 시퀀스 패턴 학습

**예시**:
```python
from transformers import AutoTokenizer, AutoModel

# 로그 메시지 임베딩
def embed_log_message(message):
    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
    model = AutoModel.from_pretrained('bert-base-uncased')
    
    tokens = tokenizer(message, return_tensors='pt')
    embedding = model(**tokens).last_hidden_state.mean(dim=1)
    
    return embedding

# 유사한 에러 메시지 클러스터링
similar_errors = cluster_similar_messages(error_messages, threshold=0.8)
```

### 4.2 중기 개선 방향

#### 4.2.1 앙상블 모델 구축

**목적**: 여러 모델의 예측을 결합하여 정확도 향상

**구현 방안**:
- **Voting 방식**: 다수결 투표
- **Weighted Voting**: 모델 성능에 따른 가중치 부여
- **Stacking**: 메타 모델을 통한 예측 결합

**예시**:
```python
class EnsembleAnomalyDetector:
    def __init__(self):
        self.models = {
            'isolation_forest': IForest(),
            'autoencoder': AutoEncoder(),
            'lof': LOF(),
            'one_class_svm': OneClassSVM()
        }
        self.weights = {
            'isolation_forest': 0.3,
            'autoencoder': 0.3,
            'lof': 0.2,
            'one_class_svm': 0.2
        }
    
    def predict(self, X):
        predictions = {}
        for name, model in self.models.items():
            predictions[name] = model.predict(X)
        
        # 가중 평균
        final_prediction = weighted_vote(predictions, self.weights)
        return final_prediction
```

#### 4.2.2 적응형 임계값 설정

**현재**: 고정된 임계값 사용
**개선**: 시간대별, 서비스별 동적 임계값

**구현 방안**:
- **시간대별 기준선**: 주간/야간, 평일/주말 등 시간대별 정상 패턴 학습
- **서비스별 기준선**: 각 서비스의 특성에 맞는 기준선 설정
- **계절성 고려**: 주기적 패턴을 고려한 기준선 조정

**예시**:
```python
# 시간대별 기준선
baselines = {
    'weekday_morning': calculate_baseline(weekday_morning_logs),
    'weekday_afternoon': calculate_baseline(weekday_afternoon_logs),
    'weekend': calculate_baseline(weekend_logs),
    'night': calculate_baseline(night_logs)
}

# 현재 시간대에 맞는 기준선 사용
current_baseline = baselines[get_time_period(current_time)]
anomalies = detect_anomalies(current_data, current_baseline)
```

#### 4.2.3 루트 원인 분석 (RCA)

**목적**: 이상치의 근본 원인 파악

**구현 방안**:
- **이상치 그룹화**: 유사한 이상치를 클러스터링
- **타임라인 분석**: 이상치 발생 전후의 이벤트 추적
- **의존성 그래프**: 서비스 간 의존성을 시각화하여 영향 범위 파악

**예시**:
```python
def root_cause_analysis(anomaly):
    # 1. 유사한 이상치 찾기
    similar_anomalies = find_similar_anomalies(anomaly, threshold=0.8)
    
    # 2. 공통 패턴 추출
    common_patterns = extract_common_patterns(similar_anomalies)
    
    # 3. 타임라인 분석
    timeline = build_timeline(anomaly, window_minutes=30)
    
    # 4. 가능한 원인 추론
    possible_causes = infer_causes(common_patterns, timeline)
    
    return {
        'anomaly': anomaly,
        'similar_count': len(similar_anomalies),
        'common_patterns': common_patterns,
        'timeline': timeline,
        'possible_causes': possible_causes
    }
```

### 4.3 장기 개선 방향

#### 4.3.1 자동 복구 시스템

**목적**: 이상치 탐지 후 자동으로 문제 해결 시도

**구현 방안**:
- **자동 스케일링**: 트래픽 급증 시 자동으로 인스턴스 확장
- **서비스 재시작**: 특정 서비스 에러 시 자동 재시작
- **트래픽 라우팅 변경**: 장애 서비스로의 트래픽 차단

**예시**:
```python
def auto_remediation(anomaly):
    if anomaly.type == 'high_error_rate':
        # 1. 트래픽 감소
        reduce_traffic(anomaly.service, ratio=0.5)
        
        # 2. 서비스 재시작
        restart_service(anomaly.service)
        
        # 3. 모니터링
        monitor_recovery(anomaly.service, duration_minutes=10)
        
        if not is_recovered(anomaly.service):
            # 복구 실패 시 알림
            escalate_to_human(anomaly)
```

#### 4.3.2 예측적 유지보수

**목적**: 장애 발생 전에 예측하여 사전 대응

**구현 방안**:
- **트렌드 분석**: 시간에 따른 지표 변화 추세 분석
- **예측 모델**: LSTM, Prophet 등을 이용한 미래 값 예측
- **조기 경고**: 예측된 문제 발생 전 경고

**예시**:
```python
from prophet import Prophet

# 에러율 예측
def predict_error_rate(historical_data, days_ahead=7):
    df = prepare_prophet_data(historical_data)
    
    model = Prophet()
    model.fit(df)
    
    future = model.make_future_dataframe(periods=days_ahead)
    forecast = model.predict(future)
    
    # 임계값 초과 예측
    if forecast['yhat'].max() > threshold:
        alert(f"7일 내 에러율 {forecast['yhat'].max():.2%} 예상")
```

#### 4.3.3 지식 그래프 구축

**목적**: 로그, 서비스, 인프라 간 관계를 그래프로 표현

**구현 방안**:
- **엔티티 추출**: 서비스, 클래스, 예외, 리소스 등을 노드로 표현
- **관계 추출**: 서비스 간 호출, 예외 발생 관계 등을 엣지로 표현
- **그래프 분석**: 그래프 알고리즘을 이용한 이상 패턴 탐지

**예시**:
```python
import networkx as nx

# 지식 그래프 구축
def build_knowledge_graph(logs):
    G = nx.DiGraph()
    
    for log in logs:
        # 노드 추가
        G.add_node(log['service'], type='service')
        G.add_node(log['class'], type='class')
        G.add_node(log['exception'], type='exception')
        
        # 엣지 추가
        G.add_edge(log['service'], log['class'], weight=1)
        G.add_edge(log['class'], log['exception'], weight=1)
    
    return G

# 그래프 기반 이상 탐지
def detect_graph_anomalies(G):
    # 중심성 분석
    centrality = nx.betweenness_centrality(G)
    
    # 이상적으로 높은 중심성을 가진 노드 탐지
    anomalies = [node for node, cent in centrality.items() 
                 if cent > threshold]
    
    return anomalies
```

### 4.4 기술 스택 확장

#### 4.4.1 빅데이터 플랫폼 통합

- **Apache Spark**: 대규모 로그 데이터 분산 처리
- **Elasticsearch**: 로그 검색 및 인덱싱
- **Kibana**: 시각화 대시보드

#### 4.4.2 MLOps 파이프라인

- **모델 버전 관리**: MLflow를 이용한 모델 버전 관리
- **자동 재학습**: 주기적 모델 재학습 및 배포
- **A/B 테스트**: 새 모델과 기존 모델 성능 비교

#### 4.4.3 클라우드 네이티브 통합

- **Kubernetes**: 컨테이너 오케스트레이션
- **Prometheus + Grafana**: 메트릭 수집 및 시각화
- **Jaeger**: 분산 추적

---

## 5. 결론

본 연구에서는 Spring Boot 로그 데이터를 활용한 이상치 탐지 시스템을 구축하였습니다. 통계적 방법과 머신러닝 기반 방법을 결합하여 다양한 이상 패턴을 탐지할 수 있는 시스템을 구현하였으며, 80% 학습 / 10% 검증 / 10% 테스트로 데이터를 분할하여 모델의 성능을 평가할 수 있도록 하였습니다.

향후 실시간 모니터링, 다중 서비스 통합 분석, 자동 복구 시스템 등의 개선을 통해 더욱 강력한 이상 탐지 및 대응 시스템으로 발전시킬 수 있을 것으로 기대됩니다.

---

## 참고 문헌

1. Liu, F. T., Ting, K. M., & Zhou, Z. H. (2008). Isolation forest. In 2008 eighth ieee international conference on data mining (pp. 413-422).

2. Aggarwal, C. C. (2017). An introduction to outlier analysis. In Outlier analysis (pp. 1-34). Springer.

3. Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A survey. ACM computing surveys (CSUR), 41(3), 1-58.

4. Spring Boot Documentation. https://spring.io/projects/spring-boot

5. PyOD: A Python Toolbox for Scalable Outlier Detection. https://pyod.readthedocs.io/

